name: E2E Contract Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

concurrency:
  group: e2e-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e-integration:
    name: E2E Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20

    strategy:
      matrix:
        node-version: [18, 20, 22]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Create test directories
        run: |
          mkdir -p test-logs
          mkdir -p test-e2e
          mkdir -p test-integration

      - name: Run E2E Integration Tests
        run: |
          npm run test -- tests/e2e/integration.test.ts
        env:
          NODE_ENV: test
          CI: true

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-integration-results-node${{ matrix.node-version }}
          path: |
            test-logs/
            test-integration/
          retention-days: 7

  e2e-contract-mock:
    name: Contract Tests with Mock Servers
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      # We might add actual external services here in the future
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Create test environment
        run: |
          mkdir -p test-e2e
          mkdir -p test-logs
          chmod 755 test-e2e test-logs

      - name: Start mock servers in background
        run: |
          # Create simple mock server for testing
          cat > test-e2e/simple-mock.js << 'EOF'
          const http = require('http');
          
          const server = http.createServer((req, res) => {
            res.setHeader('Content-Type', 'application/json');
            res.setHeader('Access-Control-Allow-Origin', '*');
            
            if (req.url === '/health') {
              res.end(JSON.stringify({ status: 'healthy', agent: 'mock' }));
            } else if (req.url === '/mcp' && req.method === 'POST') {
              let body = '';
              req.on('data', chunk => body += chunk);
              req.on('end', () => {
                try {
                  const request = JSON.parse(body);
                  if (request.method === 'tools/list') {
                    res.end(JSON.stringify({ tools: [{ name: 'mock-tool', description: 'Mock tool' }] }));
                  } else {
                    res.end(JSON.stringify({ result: 'mock-response' }));
                  }
                } catch (err) {
                  res.statusCode = 400;
                  res.end(JSON.stringify({ error: 'Invalid JSON' }));
                }
              });
            } else {
              res.statusCode = 404;
              res.end(JSON.stringify({ error: 'Not found' }));
            }
          });
          
          server.listen(3001, () => console.log('Mock server started on port 3001'));
          server.listen(3002, () => console.log('Mock server started on port 3002'));
          EOF
          
          node test-e2e/simple-mock.js &
          MOCK_PID=$!
          echo "MOCK_PID=$MOCK_PID" >> $GITHUB_ENV
          
          # Wait for mock servers to start
          sleep 3

      - name: Verify mock servers are running
        run: |
          curl -f http://localhost:3001/health || exit 1
          echo "Mock servers are responding"

      - name: Run Contract Tests
        run: |
          # Run simplified contract tests since the full mock server tests are complex
          npm run test -- tests/e2e/ --reporter=verbose
        env:
          NODE_ENV: test
          CI: true
          MOCK_SERVER_URL: http://localhost:3001

      - name: Stop mock servers
        if: always()
        run: |
          if [ ! -z "$MOCK_PID" ]; then
            kill $MOCK_PID || true
          fi
          
          # Kill any remaining processes on our ports
          pkill -f "node test-e2e/simple-mock.js" || true

      - name: Upload contract test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: contract-test-results
          path: |
            test-logs/
            test-e2e/
          retention-days: 7

  e2e-smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Run smoke tests
        run: |
          # Basic smoke test - ensure the server can start and stop
          timeout 10s node dist/src/index.js || true
          echo "Smoke test completed"

      - name: Test configuration loading
        run: |
          # Create minimal test configuration
          mkdir -p test-smoke
          echo '{"agents": {}, "settings": {}}' > test-smoke/test-config.yaml
          echo '{"profiles": {}}' > test-smoke/.mcp-config.json
          
          export MCP_YAML_CONFIG_PATH=test-smoke/test-config.yaml
          timeout 5s node dist/src/index.js || true
          echo "Configuration loading test completed"

      - name: Test with invalid configuration
        run: |
          # Test error handling with invalid config
          echo 'invalid-yaml-content' > test-smoke/invalid.yaml
          export MCP_YAML_CONFIG_PATH=test-smoke/invalid.yaml
          timeout 5s node dist/src/index.js || true
          echo "Invalid configuration handling test completed"

  e2e-performance:
    name: Performance Baseline Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Install performance testing tools
        run: |
          npm install --no-save autocannon clinic

      - name: Setup performance test environment
        run: |
          mkdir -p perf-test
          
          # Create performance test server
          cat > perf-test/perf-server.js << 'EOF'
          const http = require('http');
          
          let requestCount = 0;
          const startTime = Date.now();
          
          const server = http.createServer((req, res) => {
            requestCount++;
            
            res.setHeader('Content-Type', 'application/json');
            
            if (req.url === '/stats') {
              const uptime = Date.now() - startTime;
              res.end(JSON.stringify({ 
                requests: requestCount, 
                uptime: uptime,
                rps: Math.round(requestCount / (uptime / 1000))
              }));
            } else {
              res.end(JSON.stringify({ 
                status: 'ok', 
                request: requestCount,
                timestamp: Date.now()
              }));
            }
          });
          
          server.listen(3000, () => console.log('Performance test server started'));
          EOF

      - name: Run performance baseline tests
        run: |
          # Start performance test server
          node perf-test/perf-server.js &
          SERVER_PID=$!
          sleep 2
          
          # Run baseline performance test
          echo "Running performance baseline test..."
          npx autocannon -c 10 -d 10s --renderProgressBar false http://localhost:3000 > perf-results.txt
          
          # Get final stats
          curl http://localhost:3000/stats > final-stats.json
          
          # Stop server
          kill $SERVER_PID
          
          echo "Performance test completed"
          cat perf-results.txt
          cat final-stats.json

      - name: Validate performance metrics
        run: |
          # Basic validation of performance results
          if grep -q "requests in" perf-results.txt; then
            echo "Performance test generated results"
          else
            echo "Performance test may have failed"
            exit 1
          fi

      - name: Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: |
            perf-results.txt
            final-stats.json
          retention-days: 30

  e2e-security:
    name: Security E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run security-related E2E tests
        run: |
          # Test that security modules are working
          npm run test -- tests/ --testNamePattern="security|audit|sanitization" --reporter=verbose
        env:
          NODE_ENV: test
          CI: true

      - name: Test configuration security
        run: |
          # Ensure sensitive information isn't exposed
          mkdir -p security-test
          
          # Create test config with potential sensitive data
          cat > security-test/test-config.yaml << 'EOF'
          agents:
            test-agent:
              command: "echo"
              args: ["hello"]
              env:
                API_KEY: "test-key-should-not-be-logged"
                SECRET_TOKEN: "secret-value"
          EOF
          
          export MCP_YAML_CONFIG_PATH=security-test/test-config.yaml
          
          # Start server and capture output
          timeout 5s node dist/src/index.js > server-output.log 2>&1 || true
          
          # Check that sensitive values are not in logs
          if grep -q "test-key-should-not-be-logged" server-output.log; then
            echo "SECURITY ERROR: API key found in logs"
            exit 1
          fi
          
          if grep -q "secret-value" server-output.log; then
            echo "SECURITY ERROR: Secret token found in logs"  
            exit 1
          fi
          
          echo "Security configuration test passed"

  e2e-cross-platform:
    name: Cross-Platform E2E Tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20

    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        node-version: [20]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Run cross-platform integration tests
        run: |
          npm run test -- tests/e2e/integration.test.ts --reporter=verbose
        env:
          NODE_ENV: test
          CI: true

      - name: Test platform-specific paths
        shell: bash
        run: |
          # Create platform-specific test
          mkdir -p platform-test
          node -e "
          const path = require('path');
          const os = require('os');
          
          console.log('Platform:', os.platform());
          console.log('Home dir:', os.homedir());
          console.log('Temp dir:', os.tmpdir());
          
          // Test path resolution
          const testPath = path.join(process.cwd(), 'platform-test', 'config.yaml');
          console.log('Test config path:', testPath);
          
          // Verify path normalization works across platforms
          const normalized = path.normalize(testPath);
          console.log('Normalized path:', normalized);
          "

  generate-e2e-report:
    name: Generate E2E Test Report
    runs-on: ubuntu-latest
    needs: [e2e-integration, e2e-contract-mock, e2e-smoke-tests, e2e-performance, e2e-security, e2e-cross-platform]
    if: always()

    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-results

      - name: Generate comprehensive E2E report
        run: |
          echo "# E2E Test Report" > e2e-report.md
          echo "" >> e2e-report.md
          echo "**Generated:** $(date)" >> e2e-report.md
          echo "**Commit:** ${{ github.sha }}" >> e2e-report.md
          echo "**Branch:** ${{ github.ref_name }}" >> e2e-report.md
          echo "" >> e2e-report.md
          
          echo "## Test Results Summary" >> e2e-report.md
          echo "" >> e2e-report.md
          
          # Check job results
          echo "| Test Suite | Status |" >> e2e-report.md
          echo "|------------|--------|" >> e2e-report.md
          
          # Integration Tests
          if [ "${{ needs.e2e-integration.result }}" = "success" ]; then
            echo "| Integration Tests | ✅ PASSED |" >> e2e-report.md
          else
            echo "| Integration Tests | ❌ FAILED |" >> e2e-report.md
          fi
          
          # Contract Tests
          if [ "${{ needs.e2e-contract-mock.result }}" = "success" ]; then
            echo "| Contract Mock Tests | ✅ PASSED |" >> e2e-report.md
          else
            echo "| Contract Mock Tests | ❌ FAILED |" >> e2e-report.md
          fi
          
          # Smoke Tests
          if [ "${{ needs.e2e-smoke-tests.result }}" = "success" ]; then
            echo "| Smoke Tests | ✅ PASSED |" >> e2e-report.md
          else
            echo "| Smoke Tests | ❌ FAILED |" >> e2e-report.md
          fi
          
          # Performance Tests
          if [ "${{ needs.e2e-performance.result }}" = "success" ]; then
            echo "| Performance Tests | ✅ PASSED |" >> e2e-report.md
          else
            echo "| Performance Tests | ❌ FAILED |" >> e2e-report.md
          fi
          
          # Security Tests
          if [ "${{ needs.e2e-security.result }}" = "success" ]; then
            echo "| Security Tests | ✅ PASSED |" >> e2e-report.md
          else
            echo "| Security Tests | ❌ FAILED |" >> e2e-report.md
          fi
          
          # Cross-Platform Tests
          if [ "${{ needs.e2e-cross-platform.result }}" = "success" ]; then
            echo "| Cross-Platform Tests | ✅ PASSED |" >> e2e-report.md
          else
            echo "| Cross-Platform Tests | ❌ FAILED |" >> e2e-report.md
          fi
          
          echo "" >> e2e-report.md
          echo "## Artifacts Generated" >> e2e-report.md
          echo "" >> e2e-report.md
          
          if [ -d "test-results" ]; then
            find test-results -type f -name "*.txt" -o -name "*.json" -o -name "*.log" | while read file; do
              echo "- \`$file\`" >> e2e-report.md
            done
          fi

      - name: Upload E2E report
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-report
          path: e2e-report.md
          retention-days: 30

      - name: Comment PR with E2E results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            if (fs.existsSync('e2e-report.md')) {
              const report = fs.readFileSync('e2e-report.md', 'utf8');
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            }